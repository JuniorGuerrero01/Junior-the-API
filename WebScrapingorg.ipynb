{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d5f6b20f-3385-4555-93d0-18b85c1f08a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   Empresa JPL Title\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <h3>\n",
      "   <b id=\"boldest\">\n",
      "    Lebron James\n",
      "   </b>\n",
      "  </h3>\n",
      "  <p>\n",
      "   Salary: $92,000,000\n",
      "  </p>\n",
      "  <h3>\n",
      "   Stephen Curry\n",
      "  </h3>\n",
      "  <p>\n",
      "   Salary: $85,000,000\n",
      "  </p>\n",
      "  <h3>\n",
      "   Kevin Durant\n",
      "  </h3>\n",
      "  <p>\n",
      "   Salary: $73,200,000\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n",
      "\n",
      "obtener titulo:  <title>Empresa JPL Title</title>\n",
      "obtener jugador <h3><b id=\"boldest\">Lebron James</b></h3>\n",
      "['Lebron James', 'Stephen Curry', 'Kevin Durant']\n",
      "Lebron James\n",
      " Salary: $85,000,000 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Lebron James'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "from bs4 import BeautifulSoup # this module helps in web scrapping.\n",
    "import requests  # this module helps us to download a web page\n",
    "\n",
    "html = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <title>Empresa JPL Title</title>\n",
    "</head>\n",
    "<body>\n",
    "    <h3><b id='boldest'>Lebron James</b></h3>\n",
    "    <p> Salary: $92,000,000 </p>\n",
    "    \n",
    "    <h3>Stephen Curry</h3>\n",
    "    <p> Salary: $85,000,000 </p>\n",
    "    \n",
    "    <h3>Kevin Durant</h3>\n",
    "    <p> Salary: $73,200,000 </p>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "print(soup.prettify())\n",
    "\n",
    "obtener_titulo = soup.title\n",
    "print(\"obtener titulo: \",obtener_titulo)\n",
    "\n",
    "obtener_jugador = soup.h3\n",
    "print(\"obtener jugador\",obtener_jugador)\n",
    "\n",
    "nombre = []\n",
    "\n",
    "for h3 in soup.find_all(\"h3\"):\n",
    "    if h3.b:\n",
    "        nombre.append(h3.b.text)\n",
    "    else:\n",
    "        nombre.append(h3.text)\n",
    "print(nombre)\n",
    "\n",
    "\n",
    "obtener_titulo = soup.h3\n",
    "obtener_titulo\n",
    "\n",
    "print(obtener_titulo.b.text)\n",
    "\n",
    "tag_child = obtener_titulo.b\n",
    "tag_child\n",
    "\n",
    "\n",
    "obtener_titulo\n",
    "obtener_titulo.parent\n",
    "\n",
    "sibling_1=obtener_titulo.next_sibling\n",
    "sibling_1\n",
    "\n",
    "sibling_2=sibling_1.next_sibling\n",
    "sibling_2\n",
    "\n",
    "curry_h3 = soup.find(\"h3\",string=\"Stephen Curry\")\n",
    "\n",
    "sibling_1 = curry_h3.next_sibling\n",
    "\n",
    "sibling_2 = sibling_1.next_sibling\n",
    "\n",
    "print(sibling_2.text)\n",
    "\n",
    "tag_child['id']\n",
    "\n",
    "tag_child.attrs\n",
    "\n",
    "tag_child.get('id')\n",
    "\n",
    "tag_string=tag_child.string\n",
    "tag_string\n",
    "\n",
    "type(tag_string)\n",
    "\n",
    "unicode_string = str(tag_string)\n",
    "unicode_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6fa902c4-6803-4c27-ad7f-be65076e147f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table>\n",
      " <tr>\n",
      "  <td id=\"flight\">\n",
      "   Flight No\n",
      "  </td>\n",
      "  <td>\n",
      "   Launch site\n",
      "  </td>\n",
      "  <td>\n",
      "   Payload mass\n",
      "  </td>\n",
      " </tr>\n",
      " <tr>\n",
      "  <td class=\"API\">\n",
      "   1\n",
      "  </td>\n",
      "  <td>\n",
      "   <a href=\"https://en.wikipedia.org/wiki/Florida\">\n",
      "    Florida\n",
      "   </a>\n",
      "  </td>\n",
      "  <td>\n",
      "   300 kg\n",
      "  </td>\n",
      " </tr>\n",
      " <tr>\n",
      "  <td>\n",
      "   2\n",
      "  </td>\n",
      "  <td>\n",
      "   <a href=\"https://en.wikipedia.org/wiki/Texas\">\n",
      "    Texas\n",
      "   </a>\n",
      "  </td>\n",
      "  <td>\n",
      "   94 kg\n",
      "  </td>\n",
      " </tr>\n",
      " <tr>\n",
      "  <td>\n",
      "   3\n",
      "  </td>\n",
      "  <td>\n",
      "   <a href=\"https://en.wikipedia.org/wiki/Florida\">\n",
      "    Florida\n",
      "   </a>\n",
      "  </td>\n",
      "  <td>\n",
      "   80 kg\n",
      "  </td>\n",
      " </tr>\n",
      "</table>\n",
      "\n",
      "<class 'bs4.element.Tag'>\n",
      "row 0 is <tr>\n",
      "<td id=\"flight\">Flight No</td>\n",
      "<td>Launch site</td>\n",
      "<td>Payload mass</td>\n",
      "</tr>\n",
      "row 1 is <tr>\n",
      "<td class=\"API\">1</td>\n",
      "<td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a></td>\n",
      "<td>300 kg</td>\n",
      "</tr>\n",
      "row 2 is <tr>\n",
      "<td>2</td>\n",
      "<td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td>\n",
      "<td>94 kg</td>\n",
      "</tr>\n",
      "row 3 is <tr>\n",
      "<td>3</td>\n",
      "<td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a></td>\n",
      "<td>80 kg</td>\n",
      "</tr>\n",
      "row 0\n",
      "colunm 0 cell <td id=\"flight\">Flight No</td>\n",
      "colunm 1 cell <td>Launch site</td>\n",
      "colunm 2 cell <td>Payload mass</td>\n",
      "row 1\n",
      "colunm 0 cell <td class=\"API\">1</td>\n",
      "colunm 1 cell <td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a></td>\n",
      "colunm 2 cell <td>300 kg</td>\n",
      "row 2\n",
      "colunm 0 cell <td>2</td>\n",
      "colunm 1 cell <td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td>\n",
      "colunm 2 cell <td>94 kg</td>\n",
      "row 3\n",
      "colunm 0 cell <td>3</td>\n",
      "colunm 1 cell <td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a></td>\n",
      "colunm 2 cell <td>80 kg</td>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<b id=\"boldest\">Lebron James</b>]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "from bs4 import BeautifulSoup # this module helps in web scrapping.\n",
    "import requests  # this module helps us to download a web page\n",
    "\n",
    "table = \"\"\"\n",
    "<table>\n",
    "    <tr>\n",
    "        <td id='flight'>Flight No</td>\n",
    "        <td>Launch site</td>\n",
    "        <td>Payload mass</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td class=\"API\">1</td>\n",
    "        <td><a href='https://en.wikipedia.org/wiki/Florida'>Florida</a></td>\n",
    "        <td>300 kg</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>2</td>\n",
    "        <td><a href='https://en.wikipedia.org/wiki/Texas'>Texas</a></td>\n",
    "        <td>94 kg</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>3</td>\n",
    "        <td><a href='https://en.wikipedia.org/wiki/Florida'>Florida</a></td>\n",
    "        <td>80 kg</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "table_bs = BeautifulSoup(table, \"html.parser\")\n",
    "print(table_bs.prettify())\n",
    "\n",
    "table_rows=table_bs.find_all('tr')\n",
    "table_rows\n",
    "\n",
    "first_row =table_rows[0]\n",
    "first_row\n",
    "\n",
    "print(type(first_row))\n",
    "\n",
    "first_row.td\n",
    "\n",
    "for i,row in enumerate(table_rows):\n",
    "    print(\"row\",i,\"is\",row)\n",
    "    \n",
    "for i,row in enumerate(table_rows):\n",
    "    print(\"row\",i)\n",
    "    cells=row.find_all('td')\n",
    "    for j,cell in enumerate(cells):\n",
    "        print('colunm',j,\"cell\",cell)\n",
    "\n",
    "        list_input=table_bs .find_all(name=[\"tr\", \"td\"])\n",
    "list_input\n",
    "\n",
    "table_bs.find_all(id=\"flight\")\n",
    "\n",
    "list_input=table_bs.find_all(href=\"https://en.wikipedia.org/wiki/Texas\")\n",
    "list_input\n",
    "\n",
    "table_bs.find_all(href=True)\n",
    "\n",
    "table_bs.find_all(\"a\", href=False)\n",
    "\n",
    "soup.find_all(id=\"boldest\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "cb9f1e87-553e-4903-9ba6-37787ca02316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<table class=\"rocket\">\n",
       "<tr>\n",
       "<td>Flight No</td>\n",
       "<td>Launch site</td>\n",
       "<td>Payload mass</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>1</td>\n",
       "<td>Florida</td>\n",
       "<td>300 kg</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>2</td>\n",
       "<td>Texas</td>\n",
       "<td>94 kg</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>3</td>\n",
       "<td>Florida</td>\n",
       "<td>80 kg</td>\n",
       "</tr>\n",
       "</table>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "from bs4 import BeautifulSoup # this module helps in web scrapping.\n",
    "import requests  # this module helps us to download a web page\n",
    "\n",
    "table = \"\"\"\n",
    "<table>\n",
    "    <tr>\n",
    "        <td id='flight'>Flight No</td>\n",
    "        <td>Launch site</td>\n",
    "        <td>Payload mass</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>1</td>\n",
    "        <td><a href='https://en.wikipedia.org/wiki/Florida'>Florida</a></td>\n",
    "        <td>300 kg</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>2</td>\n",
    "        <td><a href='https://en.wikipedia.org/wiki/Texas'>Texas</a></td>\n",
    "        <td>94 kg</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>3</td>\n",
    "        <td><a href='https://en.wikipedia.org/wiki/Florida'>Florida</a></td>\n",
    "        <td>80 kg</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\"\"\"\n",
    "\n",
    "table_bs.find_all(string=\"Florida\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "c2378dd8-a0ae-46b6-bc05-36e32665a510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<table class=\"rocket\">\n",
       " <tr>\n",
       " <td>Flight No</td>\n",
       " <td>Launch site</td>\n",
       " <td>Payload mass</td>\n",
       " </tr>\n",
       " <tr>\n",
       " <td>1</td>\n",
       " <td>Florida</td>\n",
       " <td>300 kg</td>\n",
       " </tr>\n",
       " <tr>\n",
       " <td>2</td>\n",
       " <td>Texas</td>\n",
       " <td>94 kg</td>\n",
       " </tr>\n",
       " <tr>\n",
       " <td>3</td>\n",
       " <td>Florida</td>\n",
       " <td>80 kg</td>\n",
       " </tr>\n",
       " </table>]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_tables = \"\"\"\n",
    "<h3>Rocket Launch</h3>\n",
    "<p>\n",
    "    <table class='rocket'>\n",
    "        <tr>\n",
    "            <td>Flight No</td>\n",
    "            <td>Launch site</td>\n",
    "            <td>Payload mass</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>1</td>\n",
    "            <td>Florida</td>\n",
    "            <td>300 kg</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>2</td>\n",
    "            <td>Texas</td>\n",
    "            <td>94 kg</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>3</td>\n",
    "            <td>Florida</td>\n",
    "            <td>80 kg</td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</p>\n",
    "\n",
    "<h3>Pizza Party</h3>\n",
    "<p>\n",
    "    <table class='pizza'>\n",
    "        <tr>\n",
    "            <td>Pizza Place</td>\n",
    "            <td>Orders</td>\n",
    "            <td>Slices</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Domino's Pizza</td>\n",
    "            <td>10</td>\n",
    "            <td>100</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Little Caesars</td>\n",
    "            <td>12</td>\n",
    "            <td>144</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Papa John's</td>\n",
    "            <td>15</td>\n",
    "            <td>165</td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</p>\n",
    "\"\"\"\n",
    "\n",
    "two_tables_bs= BeautifulSoup(two_tables, 'html.parser')\n",
    "two_tables_bs.find(\"table\")\n",
    "\n",
    "two_tables_bs.find(\"table\",class_='pizza')\n",
    "\n",
    "two_tables_bs(\"table\",class_='rocket')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "373e73b3-64d8-4c1f-8204-348671eb142d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://web.archive.org/web/20230224123642/https://www.ibm.com/reports/threat-intelligence/\n",
      "https://web.archive.org/web/20230224123642/https://www.ibm.com/about\n",
      "https://web.archive.org/web/20230224123642/https://www.ibm.com/consulting/?lnk=flathl\n",
      "https://web.archive.org/web/20230224123642/https://www.ibm.com/consulting/strategy/?lnk=flathl\n",
      "https://web.archive.org/web/20230224123642/https://www.ibm.com/consulting/ibmix?lnk=flathl\n",
      "https://web.archive.org/web/20230224123642/https://www.ibm.com/consulting/technology/\n",
      "https://web.archive.org/web/20230224123642/https://www.ibm.com/consulting/operations/?lnk=flathl\n",
      "https://web.archive.org/web/20230224123642/https://www.ibm.com/strategic-partnerships\n",
      "https://web.archive.org/web/20230224123642/https://www.ibm.com/employment/?lnk=flatitem\n",
      "https://web.archive.org/web/20230224123642/https://www.ibm.com/impact\n",
      "https://web.archive.org/web/20230224123642/https://research.ibm.com/\n",
      "https://web.archive.org/web/20230224123642/https://www.ibm.com/\n",
      "<img alt=\"Person standing with arms crossed\" aria-describedby=\"bx--image-1\" class=\"bx--image__img\" src=\"https://web.archive.org/web/20230224123642im_/https://1.dam.s81c.com/p/0a23e414312bcb6f/08196d0e04260ae5_cropped.jpg.global.sr_16x9.jpg\"/>\n",
      "https://web.archive.org/web/20230224123642im_/https://1.dam.s81c.com/p/0a23e414312bcb6f/08196d0e04260ae5_cropped.jpg.global.sr_16x9.jpg\n",
      "<img alt=\"Team members at work in a conference room\" aria-describedby=\"bx--image-2\" class=\"bx--image__img\" src=\"https://web.archive.org/web/20230224123642im_/https://1.dam.s81c.com/p/06655c075aa3aa29/CaitOppermann_2019_12_06_IBMGarage_DSC3304.jpg.global.m_16x9.jpg\"/>\n",
      "https://web.archive.org/web/20230224123642im_/https://1.dam.s81c.com/p/06655c075aa3aa29/CaitOppermann_2019_12_06_IBMGarage_DSC3304.jpg.global.m_16x9.jpg\n",
      "<img alt=\"Coworkers looking at laptops\" aria-describedby=\"bx--image-3\" class=\"bx--image__img\" src=\"https://web.archive.org/web/20230224123642im_/https://1.dam.s81c.com/p/08f951353c2707b8/052022_CaitOppermann_InsideIBM_London_2945_03.jpg.global.sr_16x9.jpg\"/>\n",
      "https://web.archive.org/web/20230224123642im_/https://1.dam.s81c.com/p/08f951353c2707b8/052022_CaitOppermann_InsideIBM_London_2945_03.jpg.global.sr_16x9.jpg\n",
      "<img alt=\"Cloud developer with red sweater coding at desk\" aria-describedby=\"bx--image-4\" class=\"bx--image__img\" src=\"https://web.archive.org/web/20230224123642im_/https://1.dam.s81c.com/p/064e0139f5a3aa5e/0500002_Lowell_LI_100119.jpg.global.sr_16x9.jpg\"/>\n",
      "https://web.archive.org/web/20230224123642im_/https://1.dam.s81c.com/p/064e0139f5a3aa5e/0500002_Lowell_LI_100119.jpg.global.sr_16x9.jpg\n",
      "<img alt=\"Aerial view of automated conveyer belt and machinery at work\" aria-describedby=\"bx--image-5\" class=\"bx--image__img\" src=\"https://web.archive.org/web/20230224123642im_/https://1.dam.s81c.com/p/0795cae91a25156f/conveyorrobottopview.jpg.global.sr_16x9.jpg\"/>\n",
      "https://web.archive.org/web/20230224123642im_/https://1.dam.s81c.com/p/0795cae91a25156f/conveyorrobottopview.jpg.global.sr_16x9.jpg\n",
      "<img alt=\"Overhead view of partners collaborating on design with laptops and coffee\" aria-describedby=\"bx--image-6\" class=\"bx--image__img\" src=\"https://web.archive.org/web/20230224123642im_/https://1.dam.s81c.com/p/06dfa9ccdba4ec79/1f417900-9042-44d1-9c219a854bbb62ea.jpg.global.sr_16x9.jpg\"/>\n",
      "https://web.archive.org/web/20230224123642im_/https://1.dam.s81c.com/p/06dfa9ccdba4ec79/1f417900-9042-44d1-9c219a854bbb62ea.jpg.global.sr_16x9.jpg\n"
     ]
    }
   ],
   "source": [
    "## We use get to download the contents of the webpage\n",
    "## in text format and in a variable called data:\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "from bs4 import BeautifulSoup # this module helps in web scrapping.\n",
    "import requests  # this module helps us to download a web page\n",
    "\n",
    "\n",
    "url = \"https://web.archive.org/web/20230224123642/https://www.ibm.com/us-en/\"\n",
    "\n",
    "data  = requests.get(url).text \n",
    "\n",
    "soup = BeautifulSoup(data,\"html.parser\") \n",
    "\n",
    "## Get link from  a web page\n",
    "\n",
    "for link in soup.find_all(\"a\",href=True):\n",
    "    print(link.get(\"href\"))\n",
    "\n",
    "\n",
    "##Get link from a picture web page\n",
    "\n",
    "for img in soup.find_all(\"img\"):\n",
    "    print(img)\n",
    "    print(img.get(\"src\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "949272c2-02f3-412d-ab86-0cda8fbd4ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number ---->None\n",
      "1---->rgb(255,160,122)\n",
      "2---->rgb(250,128,114)\n",
      "3---->rgb(233,150,122)\n",
      "4---->rgb(240,128,128)\n",
      "5---->rgb(255,127,80)\n",
      "6---->rgb(255,99,71)\n",
      "7---->rgb(255,69,0)\n",
      "8---->rgb(255,215,0)\n",
      "9---->rgb(255,165,0)\n",
      "10---->rgb(255,140,0)\n",
      "11---->rgb(255,255,224)\n",
      "12---->rgb(255,250,205)\n",
      "13---->rgb(255,239,213)\n",
      "14---->rgb(255,228,181)\n",
      "15---->rgb(255,218,185)\n",
      "16---->rgb(238,232,170)\n",
      "17---->rgb(240,230,140)\n",
      "18---->rgb(189,183,107)\n",
      "19---->rgb(255,255,0)\n",
      "20---->rgb(124,252,0)\n",
      "21---->rgb(127,255,0)\n",
      "22---->rgb(50,205,50)\n",
      "23---->rgb(0.255.0)\n",
      "24---->rgb(34,139,34)\n",
      "25---->rgb(0,128,0)\n",
      "26---->rgb(176,224,230)\n",
      "27---->rgb(173,216,230)\n",
      "28---->rgb(135,206,250)\n",
      "29---->rgb(135,206,235)\n",
      "30---->rgb(0,191,255)\n",
      "31---->rgb(176,196,222)\n",
      "32---->rgb(30,144,255)\n"
     ]
    }
   ],
   "source": [
    "#The below url contains an html table with data about colors and color codes.\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "from bs4 import BeautifulSoup # this module helps in web scrapping.\n",
    "import requests  # this module helps us to download a web page\n",
    "\n",
    "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/datasets/HTMLColorCodes.html\"\n",
    "\n",
    "data = requests.get(url).text\n",
    "\n",
    "soup = BeautifulSoup(data,\"html.parser\")\n",
    "\n",
    "table = soup.find(\"table\")\n",
    "\n",
    "for row2 in table.find_all('tr'):\n",
    "    cols = row2.find_all('td')\n",
    "    number = cols[0].string\n",
    "    color_code = cols[4].string\n",
    "    print(\"{}---->{}\".format(number,color_code))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "44b1a491-e70d-440f-a105-7984ad7ea8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tenemos: 26 en total\n",
      "5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Country</th>\n",
       "      <th>Population</th>\n",
       "      <th>Area (km2)</th>\n",
       "      <th>Density (pop/km2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>5921231</td>\n",
       "      <td>719</td>\n",
       "      <td>8235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>165650475</td>\n",
       "      <td>148460</td>\n",
       "      <td>1116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Palestine[note 3][102]</td>\n",
       "      <td>5223000</td>\n",
       "      <td>6025</td>\n",
       "      <td>867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Taiwan[note 4]</td>\n",
       "      <td>23580712</td>\n",
       "      <td>35980</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>51844834</td>\n",
       "      <td>99720</td>\n",
       "      <td>520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Lebanon</td>\n",
       "      <td>5296814</td>\n",
       "      <td>10400</td>\n",
       "      <td>509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rwanda</td>\n",
       "      <td>13173730</td>\n",
       "      <td>26338</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Burundi</td>\n",
       "      <td>12696478</td>\n",
       "      <td>27830</td>\n",
       "      <td>456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Israel</td>\n",
       "      <td>9402617</td>\n",
       "      <td>21937</td>\n",
       "      <td>429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>India</td>\n",
       "      <td>1389637446</td>\n",
       "      <td>3287263</td>\n",
       "      <td>423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                 Country  Population  Area (km2)  Density (pop/km2)\n",
       "0     1               Singapore     5921231         719               8235\n",
       "1     2              Bangladesh   165650475      148460               1116\n",
       "2     3  Palestine[note 3][102]     5223000        6025                867\n",
       "3     4          Taiwan[note 4]    23580712       35980                655\n",
       "4     5             South Korea    51844834       99720                520\n",
       "5     6                 Lebanon     5296814       10400                509\n",
       "6     7                  Rwanda    13173730       26338                500\n",
       "7     8                 Burundi    12696478       27830                456\n",
       "8     9                  Israel     9402617       21937                429\n",
       "9    10                   India  1389637446     3287263                423"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "from bs4 import BeautifulSoup # this module helps in web scrapping.\n",
    "import requests  # this module helps us to download a web page\n",
    "\n",
    "\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/World_population\"\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                  \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                  \"Chrome/91.0.4472.124 Safari/537.36\"\n",
    "}\n",
    "\n",
    "data  = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(data.text,\"html.parser\")\n",
    "\n",
    "\n",
    "tables = soup.find_all(\"table\")\n",
    "\n",
    "print(f\"Tenemos: {len(tables)} en total\")\n",
    "\n",
    "\n",
    "for index,table in enumerate(tables):\n",
    "    if (\"10 most densely populated countries\" in str(table)):\n",
    "        table_index = index\n",
    "print(table_index)\n",
    "\n",
    "##print(tables[table_index].prettify())\n",
    "\n",
    "\n",
    "\n",
    "population_data = pd.DataFrame(columns=[\"Rank\", \"Country\", \"Population\", \"Area\", \"Density\"])\n",
    "\n",
    "for row in tables[table_index].tbody.find_all(\"tr\"):\n",
    "    col = row.find_all(\"td\")\n",
    "    if col:\n",
    "        rank = col[0].text.strip()\n",
    "        country = col[1].text.strip()\n",
    "        population = col[2].text.strip()\n",
    "        area = col[3].text.strip()\n",
    "        density = col[4].text.strip()\n",
    "\n",
    "        # Create a temporary DataFrame for the new row\n",
    "        new_row = pd.DataFrame([{\"Rank\": rank, \"Country\": country, \"Population\": population, \"Area\": area, \"Density\": density}])\n",
    "\n",
    "        # Use concat \n",
    "        population_data = pd.concat([population_data, new_row], ignore_index=True)\n",
    "\n",
    "population_data\n",
    "\n",
    "\n",
    "pd.read_html(str(tables[5]), flavor='bs4')\n",
    "\n",
    "population_data_read_html = pd.read_html(str(tables[5]), flavor='bs4')[0]\n",
    "\n",
    "population_data_read_html\n",
    "\n",
    "dataframe_list = pd.read_html(data.text, flavor='bs4')\n",
    "\n",
    "##len(dataframe_list)\n",
    "\n",
    "dataframe_list[5]\n",
    "\n",
    "heading = soup.find(\"h3\", {\"id\": \"Most_densely_populated_countries\"})\n",
    "\n",
    "# Get the next table after this heading\n",
    "table = heading.find_next(\"table\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.read_html(str(table))[0]\n",
    "print(df.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b08ad88-22a9-46f3-83db-b7e68496d966",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262db006-74a0-416f-8257-e8ce5b70b74f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
